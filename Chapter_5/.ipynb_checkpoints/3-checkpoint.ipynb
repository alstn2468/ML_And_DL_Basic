{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lab 04-2: TensorFlow로 파일에서 데이타 읽어오기 (new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n",
      "[2, 3]\n",
      "[2, 3, 4]\n",
      "[0, 1]\n",
      "[0, 1, 2, 3, 4]\n",
      "[0, 1, 2, 3]\n",
      "[0, 1, 8, 9, 4]\n"
     ]
    }
   ],
   "source": [
    "nums = list(range(5)) # Range is a built in function that creates a of integers\n",
    "print(nums)           # Prints \"[0, 1, 2, 3, 4]\"\n",
    "print(nums[2:4])      # Get a slice from index 2 to 4 (exclusive) prints \"[2, 3]\"\n",
    "print(nums[2:])       # Get a slice from index 2 to end prints \"[2, 3, 4]\"\n",
    "print(nums[:2])       # Get a slice from start to 2 (exclusive) prints \"[0, 1]\"\n",
    "print(nums[:])        # Get a slice of the whole list prints \"[0, 1, 2, 3, 4]\"\n",
    "print(nums[:-1])      # Slice indices can be negative prints \"[0, 1, 2, 3]\"\n",
    "nums[2:4] = [8, 9]    # Assign a new sublist to a slice\n",
    "print(nums)           # Prints \"[0, 1, 8, 9, 4]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing, Slicing, Iterating\n",
    "- Arrays can be indexted, sliced, iterated much like lists<br/>\n",
    "and other sequence types in Python\n",
    "- As with Python lists, slicing in Numpy can be<br/>\n",
    "accomplished with the colon(`:`) syntax\n",
    "- Colon instances(`:`) can be replaced with dots(`...`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n",
      "[2 3]\n",
      "5\n",
      "[9 9 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([1, 2, 3, 4, 5])\n",
    "print(a)      \n",
    "# [1 2 3 4 5]\n",
    "print(a[1:3]) \n",
    "# [2 3]\n",
    "print(a[-1])  \n",
    "# 5\n",
    "a[0:2] = 9\n",
    "print(a)      \n",
    "# [9 9 3 4 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]]\n",
      "[ 2  6 10]\n",
      "[ 9 10 11 12]\n",
      "[ 9 10 11 12]\n",
      "[ 9 10 11 12]\n",
      "[[1 2 3 4]\n",
      " [5 6 7 8]]\n"
     ]
    }
   ],
   "source": [
    "b = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])\n",
    "print(b)\n",
    "# [[ 1  2  3  4]\n",
    "#  [ 5  6  7  8]\n",
    "#  [ 9 10 11 12]]\n",
    "\n",
    "print(b[:, 1])\n",
    "# [ 2  6 10]\n",
    "print(b[-1])\n",
    "# [ 9 10 11 12]\n",
    "print(b[-1, :])\n",
    "# [ 9 10 11 12]\n",
    "print(b[-1, ...])\n",
    "# [ 9 10 11 12]\n",
    "print(b[0:2, :])\n",
    "# [[1 2 3 4]\n",
    "#  [5 6 7 8]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Loading data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 3) [[ 73.  80.  75.]\n",
      " [ 93.  88.  93.]\n",
      " [ 89.  91.  90.]\n",
      " [ 96.  98. 100.]\n",
      " [ 73.  66.  70.]\n",
      " [ 53.  46.  55.]\n",
      " [ 69.  74.  77.]\n",
      " [ 47.  56.  60.]\n",
      " [ 87.  79.  90.]\n",
      " [ 79.  70.  88.]\n",
      " [ 69.  70.  73.]\n",
      " [ 70.  65.  74.]\n",
      " [ 93.  95.  91.]\n",
      " [ 79.  80.  73.]\n",
      " [ 70.  73.  78.]\n",
      " [ 93.  89.  96.]\n",
      " [ 78.  75.  68.]\n",
      " [ 81.  90.  93.]\n",
      " [ 88.  92.  86.]\n",
      " [ 78.  83.  77.]\n",
      " [ 82.  86.  90.]\n",
      " [ 86.  82.  89.]\n",
      " [ 78.  83.  85.]\n",
      " [ 76.  83.  71.]\n",
      " [ 96.  93.  95.]] 25\n",
      "(25, 1) [[152.]\n",
      " [185.]\n",
      " [180.]\n",
      " [196.]\n",
      " [142.]\n",
      " [101.]\n",
      " [149.]\n",
      " [115.]\n",
      " [175.]\n",
      " [164.]\n",
      " [141.]\n",
      " [141.]\n",
      " [184.]\n",
      " [152.]\n",
      " [148.]\n",
      " [192.]\n",
      " [147.]\n",
      " [183.]\n",
      " [177.]\n",
      " [159.]\n",
      " [177.]\n",
      " [175.]\n",
      " [175.]\n",
      " [149.]\n",
      " [192.]]\n",
      "0 Cost: 83459.91 \n",
      "Prediction:\n",
      " [[428.80652]\n",
      " [508.6254 ]\n",
      " [504.6094 ]\n",
      " [549.4961 ]\n",
      " [386.36072]\n",
      " [284.1231 ]\n",
      " [413.24695]\n",
      " [309.21674]\n",
      " [473.7868 ]\n",
      " [438.21057]\n",
      " [396.19135]\n",
      " [387.69818]\n",
      " [521.2238 ]\n",
      " [432.9361 ]\n",
      " [414.14325]\n",
      " [516.72235]\n",
      " [410.28946]\n",
      " [497.39478]\n",
      " [497.9635 ]\n",
      " [446.31726]\n",
      " [483.5828 ]\n",
      " [477.58524]\n",
      " [461.6496 ]\n",
      " [432.16376]\n",
      " [528.17664]]\n",
      "200 Cost: 17.090117 \n",
      "Prediction:\n",
      " [[156.8759 ]\n",
      " [182.35207]\n",
      " [182.82706]\n",
      " [199.17577]\n",
      " [137.56065]\n",
      " [100.95138]\n",
      " [151.0479 ]\n",
      " [114.8609 ]\n",
      " [169.14423]\n",
      " [156.3639 ]\n",
      " [143.61533]\n",
      " [138.94885]\n",
      " [188.6603 ]\n",
      " [156.33766]\n",
      " [150.83678]\n",
      " [185.6988 ]\n",
      " [146.88855]\n",
      " [182.67897]\n",
      " [180.80528]\n",
      " [162.498  ]\n",
      " [176.1491 ]\n",
      " [171.58302]\n",
      " [168.45245]\n",
      " [157.71538]\n",
      " [189.88504]]\n",
      "400 Cost: 15.374473 \n",
      "Prediction:\n",
      " [[156.57225 ]\n",
      " [182.50536 ]\n",
      " [182.70175 ]\n",
      " [199.15286 ]\n",
      " [137.71259 ]\n",
      " [101.29906 ]\n",
      " [151.05412 ]\n",
      " [114.882866]\n",
      " [169.5464  ]\n",
      " [157.03372 ]\n",
      " [143.65918 ]\n",
      " [139.26428 ]\n",
      " [188.42386 ]\n",
      " [156.01375 ]\n",
      " [150.933   ]\n",
      " [185.91467 ]\n",
      " [146.60306 ]\n",
      " [182.63808 ]\n",
      " [180.48201 ]\n",
      " [162.17323 ]\n",
      " [176.19043 ]\n",
      " [171.80441 ]\n",
      " [168.41559 ]\n",
      " [157.15746 ]\n",
      " [189.90921 ]]\n",
      "600 Cost: 13.932299 \n",
      "Prediction:\n",
      " [[156.2931 ]\n",
      " [182.6473 ]\n",
      " [182.58708]\n",
      " [199.13144]\n",
      " [137.85411]\n",
      " [101.61861]\n",
      " [151.05777]\n",
      " [114.89901]\n",
      " [169.91609]\n",
      " [157.64734]\n",
      " [143.69882]\n",
      " [139.55367]\n",
      " [188.20811]\n",
      " [155.71881]\n",
      " [151.01941]\n",
      " [186.1131 ]\n",
      " [146.34483]\n",
      " [182.59712]\n",
      " [180.18636]\n",
      " [161.87575]\n",
      " [176.22652]\n",
      " [172.00786]\n",
      " [168.38005]\n",
      " [156.64696]\n",
      " [189.93275]]\n",
      "800 Cost: 12.719558 \n",
      "Prediction:\n",
      " [[156.03636 ]\n",
      " [182.77873 ]\n",
      " [182.48218 ]\n",
      " [199.11133 ]\n",
      " [137.98595 ]\n",
      " [101.91234 ]\n",
      " [151.05914 ]\n",
      " [114.909996]\n",
      " [170.25595 ]\n",
      " [158.20947 ]\n",
      " [143.73462 ]\n",
      " [139.81915 ]\n",
      " [188.01125 ]\n",
      " [155.45026 ]\n",
      " [151.0969  ]\n",
      " [186.2955  ]\n",
      " [146.11136 ]\n",
      " [182.55627 ]\n",
      " [179.91594 ]\n",
      " [161.60321 ]\n",
      " [176.25784 ]\n",
      " [172.1948  ]\n",
      " [168.3458  ]\n",
      " [156.17978 ]\n",
      " [189.95569 ]]\n",
      "1000 Cost: 11.699425 \n",
      "Prediction:\n",
      " [[155.80025 ]\n",
      " [182.90048 ]\n",
      " [182.38614 ]\n",
      " [199.09245 ]\n",
      " [138.10881 ]\n",
      " [102.1824  ]\n",
      " [151.0585  ]\n",
      " [114.916466]\n",
      " [170.56845 ]\n",
      " [158.72452 ]\n",
      " [143.7669  ]\n",
      " [140.06276 ]\n",
      " [187.8316  ]\n",
      " [155.20583 ]\n",
      " [151.16632 ]\n",
      " [186.4632  ]\n",
      " [145.90042 ]\n",
      " [182.51569 ]\n",
      " [179.66861 ]\n",
      " [161.35353 ]\n",
      " [176.28488 ]\n",
      " [172.36661 ]\n",
      " [168.31279 ]\n",
      " [155.75229 ]\n",
      " [189.97797 ]]\n",
      "1200 Cost: 10.840978 \n",
      "Prediction:\n",
      " [[155.58301]\n",
      " [183.0133 ]\n",
      " [182.29825]\n",
      " [199.07472]\n",
      " [138.22337]\n",
      " [102.4307 ]\n",
      " [151.05615]\n",
      " [114.91895]\n",
      " [170.8558 ]\n",
      " [159.19638]\n",
      " [143.79602]\n",
      " [140.28632]\n",
      " [187.66772]\n",
      " [154.98337]\n",
      " [151.22842]\n",
      " [186.6174 ]\n",
      " [145.70998]\n",
      " [182.47548]\n",
      " [179.44238]\n",
      " [161.12476]\n",
      " [176.30812]\n",
      " [172.52454]\n",
      " [168.28102]\n",
      " [155.36108]\n",
      " [189.99956]]\n",
      "1400 Cost: 10.1183 \n",
      "Prediction:\n",
      " [[155.38315 ]\n",
      " [183.11789 ]\n",
      " [182.21783 ]\n",
      " [199.05807 ]\n",
      " [138.33023 ]\n",
      " [102.65909 ]\n",
      " [151.0523  ]\n",
      " [114.917984]\n",
      " [171.12012 ]\n",
      " [159.62875 ]\n",
      " [143.82227 ]\n",
      " [140.49147 ]\n",
      " [187.51822 ]\n",
      " [154.78094 ]\n",
      " [151.2839  ]\n",
      " [186.75922 ]\n",
      " [145.53813 ]\n",
      " [182.43579 ]\n",
      " [179.23547 ]\n",
      " [160.91513 ]\n",
      " [176.32793 ]\n",
      " [172.66974 ]\n",
      " [168.25046 ]\n",
      " [155.00308 ]\n",
      " [190.02051 ]]\n",
      "1600 Cost: 9.509633 \n",
      "Prediction:\n",
      " [[155.19919 ]\n",
      " [183.21486 ]\n",
      " [182.1442  ]\n",
      " [199.04243 ]\n",
      " [138.42992 ]\n",
      " [102.86916 ]\n",
      " [151.04716 ]\n",
      " [114.913994]\n",
      " [171.3633  ]\n",
      " [160.02493 ]\n",
      " [143.84587 ]\n",
      " [140.6798  ]\n",
      " [187.38185 ]\n",
      " [154.59683 ]\n",
      " [151.33339 ]\n",
      " [186.8897  ]\n",
      " [145.38318 ]\n",
      " [182.3967  ]\n",
      " [179.04623 ]\n",
      " [160.72304 ]\n",
      " [176.34465 ]\n",
      " [172.80324 ]\n",
      " [168.22108 ]\n",
      " [154.67546 ]\n",
      " [190.04079 ]]\n",
      "1800 Cost: 8.996802 \n",
      "Prediction:\n",
      " [[155.02988]\n",
      " [183.30481]\n",
      " [182.07684]\n",
      " [199.02774]\n",
      " [138.52298]\n",
      " [103.06242]\n",
      " [151.04094]\n",
      " [114.90741]\n",
      " [171.58704]\n",
      " [160.388  ]\n",
      " [143.8671 ]\n",
      " [140.85266]\n",
      " [187.2575 ]\n",
      " [154.42941]\n",
      " [151.37744]\n",
      " [187.00974]\n",
      " [145.24362]\n",
      " [182.3583 ]\n",
      " [178.87317]\n",
      " [160.54703]\n",
      " [176.35867]\n",
      " [172.92601]\n",
      " [168.19286]\n",
      " [154.37567]\n",
      " [190.06042]]\n",
      "2000 Cost: 8.564464 \n",
      "Prediction:\n",
      " [[154.874   ]\n",
      " [183.38828 ]\n",
      " [182.01517 ]\n",
      " [199.01392 ]\n",
      " [138.60986 ]\n",
      " [103.240265]\n",
      " [151.03378 ]\n",
      " [114.898575]\n",
      " [171.79295 ]\n",
      " [160.72073 ]\n",
      " [143.88617 ]\n",
      " [141.01137 ]\n",
      " [187.14409 ]\n",
      " [154.2772  ]\n",
      " [151.4166  ]\n",
      " [187.12021 ]\n",
      " [145.118   ]\n",
      " [182.32065 ]\n",
      " [178.71487 ]\n",
      " [160.38571 ]\n",
      " [176.37025 ]\n",
      " [173.03894 ]\n",
      " [168.16574 ]\n",
      " [154.1013  ]\n",
      " [190.0794  ]]\n",
      "Your score will be  [[178.08527]]\n",
      "Other scores will be  [[177.84918]\n",
      " [179.8424 ]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "xy = np.loadtxt('data-01-test-score.csv',\n",
    "               delimiter=',',\n",
    "               dtype=np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "# Make sure the shape and data are OK\n",
    "print(x_data.shape, x_data, len(x_data))\n",
    "print(y_data.shape, y_data)\n",
    "\n",
    "# Placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplifed cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initalizaties global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# Set up feed_dict variables inside the loop.\n",
    "for step in range(2001):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                                  feed_dict={X: x_data, Y: y_data})\n",
    "    if step % 200 == 0:\n",
    "        print(step, \"Cost:\", cost_val, \"\\nPrediction:\\n\", hy_val)\n",
    "        \n",
    "# Ask my score\n",
    "print('Your score will be ', \n",
    "      sess.run(hypothesis, feed_dict={X: [[100, 70, 101]]}))\n",
    "print('Other scores will be ', \n",
    "      sess.run(hypothesis, feed_dict={X: [[60, 70, 110], [90, 100, 80]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Queue Runners\n",
    "파일이 커 메모리에 한 번에 올리기 어려울 때 사용<br/>\n",
    "여러개의 파일을 읽어와 `큐`에 삽입한 후 사용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-32fd85b1d2a6>:3: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/training/input.py:276: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/training/input.py:188: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/training/input.py:197: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/training/input.py:197: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From <ipython-input-5-32fd85b1d2a6>:5: TextLineReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TextLineDataset`.\n"
     ]
    }
   ],
   "source": [
    "filename_queue = tf.train.string_input_producer(['data-01-test-score.csv'], \n",
    "                                                shuffle=False, \n",
    "                                                name='filename_queue')\n",
    "\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "# Default values, in case of empty columns. Also specifies the type of the\n",
    "# decoded result.\n",
    "record_defaults = [[0.], [0.], [0.], [0.]]\n",
    "xy = tf.decode_csv(value, record_defaults=record_defaults)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### tf.train.batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-4e9877a8287c>:2: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n",
      "WARNING:tensorflow:From <ipython-input-6-4e9877a8287c>:28: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "0 Cost:  22151.262 \n",
      "Prediction:\n",
      " [[ 7.2209897]\n",
      " [ 8.223362 ]\n",
      " [ 8.158764 ]\n",
      " [11.476162 ]\n",
      " [ 3.9453242]\n",
      " [ 6.7052045]\n",
      " [12.457916 ]\n",
      " [14.690582 ]\n",
      " [10.668201 ]\n",
      " [15.46727  ]]\n",
      "200 Cost:  10.406 \n",
      "Prediction:\n",
      " [[153.47284 ]\n",
      " [183.99193 ]\n",
      " [181.35991 ]\n",
      " [200.02066 ]\n",
      " [138.06415 ]\n",
      " [105.453125]\n",
      " [153.46744 ]\n",
      " [119.05544 ]\n",
      " [174.82988 ]\n",
      " [167.33237 ]]\n",
      "400 Cost:  9.778231 \n",
      "Prediction:\n",
      " [[153.51967]\n",
      " [184.01764]\n",
      " [181.40793]\n",
      " [199.98935]\n",
      " [138.14502]\n",
      " [105.37993]\n",
      " [153.32802]\n",
      " [118.79093]\n",
      " [174.74454]\n",
      " [167.0656 ]]\n",
      "600 Cost:  9.226278 \n",
      "Prediction:\n",
      " [[153.55983]\n",
      " [184.04445]\n",
      " [181.4518 ]\n",
      " [199.95985]\n",
      " [138.22379]\n",
      " [105.31602]\n",
      " [153.19685]\n",
      " [118.54186]\n",
      " [174.67007]\n",
      " [166.82373]]\n",
      "800 Cost:  8.739838 \n",
      "Prediction:\n",
      " [[153.59407 ]\n",
      " [184.07213 ]\n",
      " [181.49191 ]\n",
      " [199.93213 ]\n",
      " [138.30038 ]\n",
      " [105.26045 ]\n",
      " [153.07343 ]\n",
      " [118.307274]\n",
      " [174.60542 ]\n",
      " [166.60457 ]]\n",
      "1000 Cost:  8.309912 \n",
      "Prediction:\n",
      " [[153.62297]\n",
      " [184.10042]\n",
      " [181.5286 ]\n",
      " [199.90599]\n",
      " [138.37477]\n",
      " [105.21237]\n",
      " [152.95721]\n",
      " [118.08624]\n",
      " [174.5495 ]\n",
      " [166.40598]]\n",
      "1200 Cost:  7.929006 \n",
      "Prediction:\n",
      " [[153.64714]\n",
      " [184.12914]\n",
      " [181.5621 ]\n",
      " [199.88136]\n",
      " [138.44691]\n",
      " [105.17097]\n",
      " [152.84778]\n",
      " [117.87793]\n",
      " [174.50143]\n",
      " [166.22612]]\n",
      "1400 Cost:  7.5907335 \n",
      "Prediction:\n",
      " [[153.66708 ]\n",
      " [184.15808 ]\n",
      " [181.59277 ]\n",
      " [199.85818 ]\n",
      " [138.51682 ]\n",
      " [105.135544]\n",
      " [152.74466 ]\n",
      " [117.68153 ]\n",
      " [174.46039 ]\n",
      " [166.06331 ]]\n",
      "1600 Cost:  7.2896514 \n",
      "Prediction:\n",
      " [[153.6833  ]\n",
      " [184.18712 ]\n",
      " [181.6208  ]\n",
      " [199.83633 ]\n",
      " [138.58449 ]\n",
      " [105.105484]\n",
      " [152.64752 ]\n",
      " [117.49634 ]\n",
      " [174.42561 ]\n",
      " [165.91599 ]]\n",
      "1800 Cost:  7.021037 \n",
      "Prediction:\n",
      " [[153.6962  ]\n",
      " [184.21611 ]\n",
      " [181.64644 ]\n",
      " [199.81572 ]\n",
      " [138.64989 ]\n",
      " [105.080185]\n",
      " [152.55595 ]\n",
      " [117.32164 ]\n",
      " [174.39641 ]\n",
      " [165.7827  ]]\n",
      "2000 Cost:  6.780886 \n",
      "Prediction:\n",
      " [[153.70616 ]\n",
      " [184.24493 ]\n",
      " [181.66989 ]\n",
      " [199.7963  ]\n",
      " [138.71309 ]\n",
      " [105.05913 ]\n",
      " [152.4696  ]\n",
      " [117.156815]\n",
      " [174.3722  ]\n",
      " [165.6622  ]]\n",
      "Your score will be  [[184.30801]]\n",
      "Other scores will be  [[192.92122]\n",
      " [173.19138]]\n"
     ]
    }
   ],
   "source": [
    "# collect batches of csv in\n",
    "train_x_batch, train_y_batch = \\\n",
    "    tf.train.batch([xy[0:-1], xy[-1:]], batch_size=10)\n",
    "\n",
    "# placeholders for a tensor that will be always fed.\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "# Simplified cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Start populating the filename queue.\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "for step in range(2001):\n",
    "    x_batch, y_batch = sess.run([train_x_batch, train_y_batch])\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train], \n",
    "                                   feed_dict={X: x_batch, Y: y_batch})\n",
    "    if step % 200 == 0:\n",
    "        print(step, \"Cost: \", cost_val, \"\\nPrediction:\\n\", hy_val)\n",
    "\n",
    "coord.request_stop()\n",
    "coord.join(threads)\n",
    "\n",
    "# Ask my score\n",
    "print(\"Your score will be \",\n",
    "      sess.run(hypothesis, feed_dict={X: [[100, 70, 101]]}))\n",
    "\n",
    "print(\"Other scores will be \",\n",
    "      sess.run(hypothesis, feed_dict={X: [[60, 70, 110], [90, 100, 80]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### shuffle_batch\n",
    "\n",
    "```python\n",
    "# min_after_dequeue defines how big a buffer we will randomly sample\n",
    "#   from -- bigger means better shuffling but slower start up and more\n",
    "#   memory used.\n",
    "# capacity must be Larger than min_after_dequeue and the amount Larger\n",
    "#   determines the maximum we will prefetch. Recommendation:\n",
    "#   min_after_dequeue + (num_threads + a small safety margin) * batch_size\n",
    "min_after_dequeue = 10000\n",
    "capacity = min_after_dequeue + 3 * batch_size\n",
    "example_batch, label_batch = tf.train.shuffle_batch([example, label],\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    capacity=capacity,\n",
    "                                                    min_after_dequeue=min_after_dequeue)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
