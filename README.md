# 머신러닝과 딥러닝 BASIC
## Soonchunhyang University
Department of<br/> Computer Software Engineering
------------------------------------------

##  [김민수](https://github.com/alstn2468)
## [ [Facebook](https://www.facebook.com/profile.php?id=100003769223078) ] [ [Github](https://github.com/alstn2468) ] [ [LinkedIn](https://www.linkedin.com/in/minsu-kim-336289160/) ] [ [Blog](https://alstn2468.github.io/) ]<br/>

[Edwith](https://www.edwith.org)에서 제공하는 HKUST 김성훈 교수님의<br/>
[머신러닝과 딥러닝 BASIC](https://www.edwith.org/others26/joinLectures/9829)강의를 공부하며 **요약 정리**한 레파지토리 입니다.

해당 레파지토리에 업로드한 Markdown 자료들을 블로그 포스트에 사용할 예정<br/>


### 강의 목록
#### 오리엔테이션
- 수업소개와 개요


#### 머신러닝의 개념과 용어
- 기본적인 Machine Learnnig 의 용어와 개념 설명
- TensorFlow의 설치및 기본적인 operations (new)


#### Linear Regression 의 개념
- Linear Regression의 Hypothesis 와 cost
- Tensorflow로 간단한 linear regression을 구현 (new)


#### Linear Regression cost 함수 최소화
- Linear Regression의 cost 최소화 알고리즘의 원리
- Linear Regression 의 cost 최소화의 TensorFlow 구현(new)


#### 여러개의 입력(feature)의 Linear Regression
- multi-variable linear regression (new)
- lab 04-1: multi-variable linear regression을 TensorFlow에서 구현하기
- lab 04-2: TensorFlow로 파일에서 데이타 읽어오기 (new)


#### Logistic (Regression) Classification
- Logistic Classification의 가설 함수 정의
- Logistic Regression의 cost 함수 설명
- TensorFlow로 Logistic Classification의 구현하기(new)


#### Softmax Regression (Multinomial Logistic Regression)
- Multinomial 개념 소개
- Cost 함수 소개
- lab 06-1: TensorFlow로 Softmax Classification의 구현하기 (new)
- lab 06-2: TensorFlow로 Fancy Softmax Classification의 구현하기 (new)


#### ML의 실용과 몇가지 팁
- 학습 rate, Overfitting, 그리고 일반화 (Regularization)
- Training/Testing 데이타 셋
- lab 07-1: training/test dataset, learning rate, normalization (new)
- lab 07-2: Meet MNIST Dataset (new)


#### 딥러닝의 기본 개념과, 문제, 그리고 해결
- 딥러닝의 기본 개념: 시작과 XOR 문제
- 딥러닝의 기본 개념2: Back-propagation 과 2006/2007 ‘딥’의 출현
- Lab : Tensor Manipulation (new)


#### Neural Network 1: XOR 문제와 학습방법, Backpropagation
- XOR 문제 딥러닝으로 풀기
- 특별편: 10분안에 미분 정리하기
- 딥넷트웍 학습 시키기 (backpropagation)
- Lab 9-1: XOR을 위한 텐스플로우 딥넷트웍 (new)
- Lab 9-2: Tensor Board로 딥네트웍 들여다보기 (new)


#### Neural Network 2: ReLU and 초기값 정하기 (2006/2007 breakthrough)
- XSigmoid 보다 ReLU가 더 좋아
- Weight 초기화 잘해보자
- Dropout 과 앙상블
- 레고처럼 넷트웍 모듈을 마음껏 쌓아 보자
- Lab 10: 딥러닝으로 MNIST 98%이상 해보기(new)


#### Convolutional Neural Networks
- ConvNet의 Conv 레이어 만들기
- ConvNet Max pooling 과 Full Network
- Google Cloud ML with Examples 1
- ConvNet의 활용 예
- Lab 11 : ConvNet을 TensorFlow로 구현하자 (MNIST 99%)


#### Recurrent Neural Network
- NN의 꽃 RNN 이야기
- 실습: TensorFlow에서 RNN 구현하기


#### Deep Deep Network AWS 에서 GPU와 돌려보기 (powered bt AWS)
- powered by AWS


#### AWS 에서 저렴하게 Spot Instance 를 터미네이션 걱정없이 사용하기
- AWS에서 저렴하게 Spot Instance를 터미네이션 걱정없이 사용하기


#### Google Cloud ML을 이용해 TensorFlow 실행하기
- Google Cloud ML을 이용해 TensorFlow 실행하기
