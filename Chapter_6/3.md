
## TensorFlow로 Logistic Classification 구현하기(new)

### Logistic Regression
\begin{align}
H(X) = \frac{1}{1 + e^{-W^{T}X}} \\
\end{align}

\begin{align}
cost(W) = -\frac{1}{m}\sum ylog(H(x)) + (1 - y)log(1 - H(x)) \\
\end{align}

\begin{align}
W := W - \alpha \frac{\sigma}{\sigma W}cost(W) \\
\end{align}


```python
import tensorflow as tf
```

    /anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
      from ._conv import register_converters as _register_converters


<br/>

### Training Data
`y`의 값은 **0 또는 1**의 Binary 값


```python
x_data = [
    [1, 2], [2, 3], [3, 1], 
    [4, 3], [5, 3], [6, 2],
]
y_data = [
    [0], [0], [0],
    [1], [1], [1],
]

# placeholders for a tensor that will be always fed.
X = tf.placeholder(tf.float32, shape=[None, 2])
Y = tf.placeholder(tf.float32, shape=[None, 1])
```

<br/>

### Hypothesis
\begin{align}
H(X) = \frac{1}{1 + e^{-W^{T}X}} \\
\end{align}

`W`의 `shape`은 **[들어오는 데이터 개수, 나가는 데이터 개수]**<br/>
`b`의 `shape`은 **나가는 데이터 개수**


```python
W = tf.Variable(tf.random_normal([2, 1]), name="weight")
b = tf.Variable(tf.random_normal([1]), name="bias")

# Hypothesis using sigmoid : tf.div(1., 1. + tf.exp(tf.matmul(X, W) + b))
hypothesis = tf.sigmoid(tf.matmul(X, W) + b)
```

<br/>

### Cost Function
\begin{align}
cost(W) = -\frac{1}{m}\sum ylog(H(x)) + (1 - y)log(1 - H(x)) \\
\end{align}


```python
# Cost/Loss function
cost = -tf.reduce_mean(Y * tf.log(hypothesis) 
                       + (1 - Y) * tf.log(1 - hypothesis))
```

<br/>

### Optimizing with Gradient Descent
\begin{align}
W := W - \alpha \frac{\sigma}{\sigma W}cost(W) \\
\end{align}


```python
train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)
```

<br/>

### Accuuracy computtation


```python
# True if hypothesis > 0.5 else False
predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)
accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))
```

<br/>

### Train the model


```python
# Launch graph
with tf.Session() as sess:
    # Initialize Tenserflow variables
    sess.run(tf.global_variables_initializer())
    
    for step in range(10001):
        cost_val, _ = sess.run([cost, train],
                              feed_dict={X: x_data, Y: y_data})
        
        if step % 1000 == 0:
            print(step, cost_val)
            
    # Accuracy report
    h, c, a = sess.run([hypothesis, predicted, accuracy],
                      feed_dict={X: x_data, Y: y_data})
    print("\nHypothesis : ", h,
         "\nCorrect (Y) : ", c,
         "\nAccuracy : ", a)
```

    0 0.8831861
    1000 0.30194607
    2000 0.2640162
    3000 0.2339095
    4000 0.20963901
    5000 0.18977194
    6000 0.17327213
    7000 0.15938494
    8000 0.14755455
    9000 0.13736634
    10000 0.12850672
    
    Hypothesis :  [[0.02243203]
     [0.14577791]
     [0.26223317]
     [0.80160093]
     [0.95159554]
     [0.98427284]] 
    Correct (Y) :  [[0.]
     [0.]
     [0.]
     [1.]
     [1.]
     [1.]] 
    Accuracy :  1.0


<br/>

### Classifying diabetes


```python
import numpy as np

xy = np.loadtxt('data-03-diabetes.csv',
               delimiter=',',
               dtype=np.float32)
x_data = xy[:, 0:-1]
y_data = xy[:, [-1]]
```


```python
# placeholders for a tensor that will be always fed.
X = tf.placeholder(tf.float32, shape=[None, 8])
Y = tf.placeholder(tf.float32, shape=[None, 1])

W = tf.Variable(tf.random_normal([8, 1]), name="weight")
b = tf.Variable(tf.random_normal([1]), name="bias")

# Hypothesis using sigmoid : tf.div(1., 1. + tf.exp(tf.matmul(X, W)))
hypothesis = tf.sigmoid(tf.matmul(X, W) + b)

# Cost/Loss function
cost = -tf.reduce_mean(Y * tf.log(hypothesis)
                      + (1 - Y) * tf.log(1 - hypothesis))

# Optimizing with Gradient Descent
train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)

# Accuracy computation, True if hypothesis > 0.5 else False
predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)
accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))

# Launch Graph
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    
    feed = {X: x_data, Y: y_data}
    
    for step in range(10001):
        sess.run(train, feed_dict=feed)
        
        if step % 1000 == 0:
            print(step, sess.run(cost, feed_dict=feed))
            
    # Accuracy report
    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict=feed)
    print("\nHypothesis : ", h,
         "\nCorrect (Y) : ", c,
         "\nAccuracy : ", a)
```

    0 0.899115
    1000 0.5735633
    2000 0.5399573
    3000 0.5193476
    4000 0.5059997
    5000 0.49698162
    6000 0.49068317
    7000 0.48616815
    8000 0.48286337
    9000 0.48040378
    10000 0.4785474
    
    Hypothesis :  [[0.38358444]
     [0.92869014]
     [0.22825797]
     [0.93518037]
     [0.10852826]
     [0.787232  ]
     [0.9218224 ]
     [0.5370475 ]
     [0.22235288]
     [0.58532554]
     [0.7563662 ]
     [0.16214497]
     [0.28535488]
     [0.22292668]
     [0.715882  ]
     [0.4566469 ]
     [0.74745923]
     [0.7087745 ]
     [0.8117335 ]
     [0.64360595]
     [0.6781297 ]
     [0.11629537]
     [0.70068216]
     [0.6537068 ]
     [0.33199382]
     [0.9449027 ]
     [0.5891875 ]
     [0.70406467]
     [0.6685961 ]
     [0.47938004]
     [0.95094585]
     [0.92311436]
     [0.6121467 ]
     [0.8260642 ]
     [0.37224534]
     [0.646797  ]
     [0.81102914]
     [0.51438195]
     [0.42212456]
     [0.38334653]
     [0.88059723]
     [0.19786389]
     [0.37716255]
     [0.05471164]
     [0.5385413 ]
     [0.94200104]
     [0.6673482 ]
     [0.68329626]
     [0.96004236]
     [0.9231035 ]
     [0.9355266 ]
     [0.25386885]
     [0.31512013]
     [0.9532639 ]
     [0.17026478]
     [0.5018234 ]
     [0.13977583]
     [0.65864277]
     [0.83452433]
     [0.48667055]
     [0.9481998 ]
     [0.70706546]
     [0.62005216]
     [0.8639901 ]
     [0.66317   ]
     [0.60235244]
     [0.9642639 ]
     [0.7535737 ]
     [0.8546952 ]
     [0.6633986 ]
     [0.2769991 ]
     [0.7679933 ]
     [0.9299653 ]
     [0.9135071 ]
     [0.88641137]
     [0.7847674 ]
     [0.33811414]
     [0.8781557 ]
     [0.87426686]
     [0.9090308 ]
     [0.88624156]
     [0.83624446]
     [0.43712312]
     [0.8326604 ]
     [0.48518074]
     [0.8588396 ]
     [0.35864374]
     [0.9078545 ]
     [0.932034  ]
     [0.7972444 ]
     [0.773362  ]
     [0.65706444]
     [0.7649187 ]
     [0.5573284 ]
     [0.89538395]
     [0.974031  ]
     [0.86720425]
     [0.60665303]
     [0.24617603]
     [0.64418596]
     [0.7195454 ]
     [0.96596944]
     [0.7508909 ]
     [0.71327007]
     [0.9582323 ]
     [0.63900334]
     [0.90623814]
     [0.8434402 ]
     [0.4995852 ]
     [0.29049766]
     [0.9417074 ]
     [0.85972506]
     [0.35603616]
     [0.49255237]
     [0.62461555]
     [0.7877343 ]
     [0.86387163]
     [0.9309887 ]
     [0.11604828]
     [0.70303154]
     [0.86532795]
     [0.62632674]
     [0.6536208 ]
     [0.6061622 ]
     [0.66193706]
     [0.8142311 ]
     [0.8445073 ]
     [0.6493651 ]
     [0.5092369 ]
     [0.35851786]
     [0.39206305]
     [0.75958556]
     [0.94690526]
     [0.79780835]
     [0.771738  ]
     [0.84408265]
     [0.5057738 ]
     [0.7897179 ]
     [0.7703196 ]
     [0.7317643 ]
     [0.8516123 ]
     [0.5916011 ]
     [0.537085  ]
     [0.6881422 ]
     [0.9135119 ]
     [0.7498713 ]
     [0.42113176]
     [0.93955517]
     [0.64037216]
     [0.7928342 ]
     [0.30435547]
     [0.42243373]
     [0.08742994]
     [0.22916287]
     [0.8898132 ]
     [0.87501043]
     [0.9509773 ]
     [0.08886664]
     [0.6041262 ]
     [0.7482316 ]
     [0.59354657]
     [0.84721893]
     [0.49927032]
     [0.8142368 ]
     [0.60762745]
     [0.6484976 ]
     [0.71865565]
     [0.9079216 ]
     [0.79706436]
     [0.6102605 ]
     [0.8869913 ]
     [0.8467155 ]
     [0.9478291 ]
     [0.22149368]
     [0.8296477 ]
     [0.2557624 ]
     [0.3374676 ]
     [0.41993418]
     [0.90932643]
     [0.6453444 ]
     [0.9252844 ]
     [0.9045975 ]
     [0.6144223 ]
     [0.12228866]
     [0.16505796]
     [0.72903234]
     [0.76904243]
     [0.67800164]
     [0.81878966]
     [0.59202397]
     [0.3385018 ]
     [0.13053364]
     [0.8797435 ]
     [0.40903696]
     [0.84522754]
     [0.9082498 ]
     [0.7045461 ]
     [0.6039686 ]
     [0.64174235]
     [0.58747447]
     [0.7232668 ]
     [0.95661044]
     [0.7225852 ]
     [0.8426126 ]
     [0.11361366]
     [0.3871605 ]
     [0.88346976]
     [0.22192602]
     [0.9318903 ]
     [0.292458  ]
     [0.2859427 ]
     [0.40722886]
     [0.7248754 ]
     [0.17400154]
     [0.7231237 ]
     [0.71808714]
     [0.83675617]
     [0.6143943 ]
     [0.11475439]
     [0.39208904]
     [0.68992007]
     [0.4504621 ]
     [0.93425184]
     [0.944193  ]
     [0.70267725]
     [0.29773793]
     [0.04137846]
     [0.63602203]
     [0.3898668 ]
     [0.4048831 ]
     [0.96501935]
     [0.62167454]
     [0.95183396]
     [0.20411196]
     [0.15985925]
     [0.3315646 ]
     [0.81985027]
     [0.90031475]
     [0.88629854]
     [0.63003635]
     [0.6242349 ]
     [0.5907765 ]
     [0.17632507]
     [0.52242297]
     [0.13350667]
     [0.5469541 ]
     [0.9031147 ]
     [0.5836815 ]
     [0.7707274 ]
     [0.96387446]
     [0.7971679 ]
     [0.74378055]
     [0.7226816 ]
     [0.73948747]
     [0.86569303]
     [0.35577413]
     [0.39786932]
     [0.50820833]
     [0.8281822 ]
     [0.6415036 ]
     [0.64939183]
     [0.8130901 ]
     [0.28968212]
     [0.4647438 ]
     [0.5497614 ]
     [0.6155614 ]
     [0.4244815 ]
     [0.89031714]
     [0.8049671 ]
     [0.9300796 ]
     [0.49883235]
     [0.7638981 ]
     [0.8035795 ]
     [0.8219076 ]
     [0.68962693]
     [0.87371486]
     [0.32560325]
     [0.5654856 ]
     [0.7267813 ]
     [0.39760894]
     [0.8313555 ]
     [0.31627622]
     [0.63412035]
     [0.93630517]
     [0.77209014]
     [0.8591702 ]
     [0.6550491 ]
     [0.49656102]
     [0.5505635 ]
     [0.3133578 ]
     [0.419552  ]
     [0.66538423]
     [0.6887774 ]
     [0.6215462 ]
     [0.62904257]
     [0.18703406]
     [0.64939237]
     [0.9132772 ]
     [0.52297413]
     [0.684328  ]
     [0.7585538 ]
     [0.45062017]
     [0.7009901 ]
     [0.52640545]
     [0.71014017]
     [0.89537716]
     [0.6436055 ]
     [0.73423815]
     [0.83183444]
     [0.57117295]
     [0.851155  ]
     [0.9598591 ]
     [0.32634813]
     [0.757582  ]
     [0.26061553]
     [0.7597451 ]
     [0.82698536]
     [0.69915843]
     [0.42889503]
     [0.77002996]
     [0.7703182 ]
     [0.72849274]
     [0.1617552 ]
     [0.82702786]
     [0.8430812 ]
     [0.61185277]
     [0.9318309 ]
     [0.189637  ]
     [0.7298491 ]
     [0.9508516 ]
     [0.18748707]
     [0.41735935]
     [0.6934426 ]
     [0.34852085]
     [0.17845592]
     [0.8667196 ]
     [0.9298109 ]
     [0.86477363]
     [0.6652992 ]
     [0.61939263]
     [0.58353186]
     [0.72281116]
     [0.8220983 ]
     [0.938206  ]
     [0.7347169 ]
     [0.76720524]
     [0.6439237 ]
     [0.9400085 ]
     [0.9425537 ]
     [0.70657086]
     [0.30745777]
     [0.63426465]
     [0.2686333 ]
     [0.72978246]
     [0.21973273]
     [0.23753798]
     [0.38102332]
     [0.75168777]
     [0.33533517]
     [0.57203305]
     [0.8027488 ]
     [0.67653024]
     [0.84326744]
     [0.96392274]
     [0.82449627]
     [0.12120374]
     [0.43176952]
     [0.7972516 ]
     [0.83308125]
     [0.61315393]
     [0.25664648]
     [0.9113332 ]
     [0.88139886]
     [0.256256  ]
     [0.68566614]
     [0.8616177 ]
     [0.86975026]
     [0.854755  ]
     [0.9144662 ]
     [0.89128494]
     [0.9154641 ]
     [0.69511503]
     [0.6556278 ]
     [0.56007963]
     [0.84427446]
     [0.866325  ]
     [0.213172  ]
     [0.80044496]
     [0.8916546 ]
     [0.36534813]
     [0.6304005 ]
     [0.85538477]
     [0.52837366]
     [0.9308946 ]
     [0.26669717]
     [0.8197333 ]
     [0.6532666 ]
     [0.88392293]
     [0.31488928]
     [0.5936445 ]
     [0.72237927]
     [0.8004662 ]
     [0.11547218]
     [0.20287035]
     [0.74461806]
     [0.82905227]
     [0.50877666]
     [0.793081  ]
     [0.40516073]
     [0.41162694]
     [0.8712263 ]
     [0.47417462]
     [0.9394584 ]
     [0.8167123 ]
     [0.6984427 ]
     [0.916346  ]
     [0.57659566]
     [0.7689996 ]
     [0.3121647 ]
     [0.28678358]
     [0.72142   ]
     [0.38839293]
     [0.5227999 ]
     [0.90421295]
     [0.9037276 ]
     [0.9170964 ]
     [0.9581307 ]
     [0.7322389 ]
     [0.90620685]
     [0.29048604]
     [0.36845684]
     [0.51541346]
     [0.9473159 ]
     [0.6561935 ]
     [0.23820554]
     [0.93025374]
     [0.8003683 ]
     [0.5915066 ]
     [0.7900606 ]
     [0.0184541 ]
     [0.9338559 ]
     [0.78582954]
     [0.73882365]
     [0.77685446]
     [0.9694569 ]
     [0.6676639 ]
     [0.7474692 ]
     [0.7099186 ]
     [0.81676024]
     [0.15007444]
     [0.55627155]
     [0.9117084 ]
     [0.56511766]
     [0.76684713]
     [0.94969153]
     [0.83362895]
     [0.8980183 ]
     [0.6616757 ]
     [0.7462703 ]
     [0.92941016]
     [0.7202547 ]
     [0.5987894 ]
     [0.29739735]
     [0.4967917 ]
     [0.5258038 ]
     [0.57703656]
     [0.5785218 ]
     [0.77639693]
     [0.5954364 ]
     [0.81289905]
     [0.8567499 ]
     [0.7500248 ]
     [0.68101394]
     [0.4699417 ]
     [0.6353964 ]
     [0.9284204 ]
     [0.8549291 ]
     [0.19647479]
     [0.39261264]
     [0.41699085]
     [0.0873605 ]
     [0.9020166 ]
     [0.15188427]
     [0.89375114]
     [0.90035474]
     [0.8238246 ]
     [0.69117326]
     [0.8791041 ]
     [0.33970386]
     [0.788192  ]
     [0.94604796]
     [0.28747395]
     [0.45900217]
     [0.9039191 ]
     [0.8705921 ]
     [0.6162381 ]
     [0.78579426]
     [0.81214714]
     [0.819016  ]
     [0.30889592]
     [0.7285797 ]
     [0.86410505]
     [0.62943417]
     [0.77875507]
     [0.6763221 ]
     [0.79466283]
     [0.87196624]
     [0.9228989 ]
     [0.60461724]
     [0.45846954]
     [0.718733  ]
     [0.8151281 ]
     [0.9717164 ]
     [0.7952107 ]
     [0.66224056]
     [0.38260308]
     [0.6859242 ]
     [0.91641927]
     [0.9508483 ]
     [0.90837383]
     [0.69767344]
     [0.6730251 ]
     [0.8042912 ]
     [0.45807278]
     [0.7971515 ]
     [0.78399247]
     [0.8866215 ]
     [0.588403  ]
     [0.7511089 ]
     [0.8772425 ]
     [0.52906245]
     [0.6179532 ]
     [0.6312149 ]
     [0.7421923 ]
     [0.67092866]
     [0.92058206]
     [0.9339238 ]
     [0.24425109]
     [0.11854582]
     [0.74922556]
     [0.5412127 ]
     [0.37996605]
     [0.83507556]
     [0.90722895]
     [0.7234883 ]
     [0.9347857 ]
     [0.9061849 ]
     [0.76524854]
     [0.82875824]
     [0.68826485]
     [0.46296638]
     [0.76978564]
     [0.5831379 ]
     [0.09870809]
     [0.89825726]
     [0.8714632 ]
     [0.7527517 ]
     [0.91331583]
     [0.8428286 ]
     [0.8533452 ]
     [0.5840169 ]
     [0.65526676]
     [0.8810204 ]
     [0.80954665]
     [0.8452553 ]
     [0.89560115]
     [0.68619055]
     [0.7300278 ]
     [0.7852422 ]
     [0.5288223 ]
     [0.51920885]
     [0.08239   ]
     [0.26165548]
     [0.8252926 ]
     [0.62899053]
     [0.6507457 ]
     [0.5645968 ]
     [0.93729556]
     [0.38737082]
     [0.82055014]
     [0.31288937]
     [0.9011081 ]
     [0.3214235 ]
     [0.7852942 ]
     [0.59080106]
     [0.8557567 ]
     [0.5888349 ]
     [0.28144592]
     [0.74702007]
     [0.87797666]
     [0.36643296]
     [0.89359045]
     [0.9120931 ]
     [0.84984934]
     [0.83074284]
     [0.40477473]
     [0.29221603]
     [0.62750995]
     [0.21096067]
     [0.95624024]
     [0.34753793]
     [0.9278199 ]
     [0.85792667]
     [0.36835852]
     [0.23152813]
     [0.74183136]
     [0.39906916]
     [0.8554612 ]
     [0.7899913 ]
     [0.98137164]
     [0.59682804]
     [0.5978143 ]
     [0.8114339 ]
     [0.8573951 ]
     [0.09404772]
     [0.6784412 ]
     [0.77475804]
     [0.8692159 ]
     [0.6164473 ]
     [0.46066296]
     [0.60526216]
     [0.8948087 ]
     [0.63127905]
     [0.79138565]
     [0.8176325 ]
     [0.89226776]
     [0.78856075]
     [0.5600209 ]
     [0.79038894]
     [0.9158394 ]
     [0.6974972 ]
     [0.9666435 ]
     [0.8433426 ]
     [0.6226161 ]
     [0.504053  ]
     [0.8251609 ]
     [0.86935425]
     [0.46509883]
     [0.701803  ]
     [0.17538516]
     [0.5998416 ]
     [0.7998604 ]
     [0.9428865 ]
     [0.81477207]
     [0.7342592 ]
     [0.7349205 ]
     [0.88854223]
     [0.4126339 ]
     [0.93202716]
     [0.59678125]
     [0.879602  ]
     [0.3333787 ]
     [0.09619869]
     [0.35827997]
     [0.34921813]
     [0.6423691 ]
     [0.8496715 ]
     [0.5726471 ]
     [0.73201334]
     [0.7601192 ]
     [0.497501  ]
     [0.33966666]
     [0.88593066]
     [0.9215844 ]
     [0.44887346]
     [0.65370625]
     [0.18553129]
     [0.437857  ]
     [0.70273453]
     [0.63762975]
     [0.90324396]
     [0.97665954]
     [0.16625205]
     [0.66616285]
     [0.6581229 ]
     [0.43553898]
     [0.74571335]
     [0.7547589 ]
     [0.8680974 ]
     [0.7820558 ]
     [0.46601865]
     [0.7172281 ]
     [0.2173857 ]
     [0.6802295 ]
     [0.47634494]
     [0.9114828 ]
     [0.622409  ]
     [0.58653283]
     [0.79168177]
     [0.7756396 ]
     [0.4448875 ]
     [0.76821584]
     [0.66892487]
     [0.37090668]
     [0.5378888 ]
     [0.89806485]
     [0.8433975 ]
     [0.5391709 ]
     [0.7175815 ]
     [0.28513443]
     [0.83353496]
     [0.583816  ]
     [0.774162  ]
     [0.3329831 ]
     [0.5917075 ]
     [0.8473725 ]
     [0.1276211 ]
     [0.33256516]
     [0.8070793 ]
     [0.79440725]
     [0.7772855 ]
     [0.9276509 ]
     [0.7405661 ]
     [0.688033  ]
     [0.7385463 ]
     [0.82124895]
     [0.68927526]
     [0.8142723 ]
     [0.54975504]
     [0.569551  ]
     [0.86365515]
     [0.82062167]
     [0.7166321 ]
     [0.3211108 ]
     [0.8683431 ]
     [0.8347557 ]
     [0.8062445 ]
     [0.7057985 ]
     [0.88100314]
     [0.8233751 ]
     [0.75604784]
     [0.38913724]
     [0.8534568 ]
     [0.90455055]
     [0.40011317]
     [0.17607643]
     [0.74703175]
     [0.4406432 ]
     [0.79000634]
     [0.3033449 ]
     [0.41360813]
     [0.47358236]
     [0.78020144]
     [0.8695359 ]
     [0.1537763 ]
     [0.3795958 ]
     [0.6702843 ]
     [0.5631636 ]
     [0.46744844]
     [0.79770285]
     [0.16813281]
     [0.9151287 ]
     [0.15277003]
     [0.845123  ]
     [0.68586665]
     [0.7215009 ]
     [0.84273595]
     [0.6738128 ]
     [0.90443367]] 
    Correct (Y) :  [[0.]
     [1.]
     [0.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [0.]
     [0.]
     [0.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [0.]
     [0.]
     [1.]
     [0.]
     [0.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [0.]
     [1.]
     [0.]
     [1.]
     [0.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [0.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [0.]
     [1.]
     [1.]
     [0.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [0.]
     [0.]
     [0.]
     [0.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [0.]
     [0.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [0.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [0.]
     [1.]
     [0.]
     [1.]
     [0.]
     [0.]
     [0.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [0.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [0.]
     [0.]
     [1.]
     [0.]
     [0.]
     [1.]
     [1.]
     [1.]
     [0.]
     [0.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [0.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [0.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [0.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [0.]
     [0.]
     [1.]
     [0.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [0.]
     [1.]
     [0.]
     [0.]
     [0.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [0.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [0.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [0.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [0.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [0.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [0.]
     [0.]
     [0.]
     [0.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [0.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [0.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [0.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [0.]
     [1.]
     [0.]
     [1.]
     [0.]
     [1.]
     [1.]
     [0.]
     [0.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [0.]
     [0.]
     [0.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [0.]
     [1.]
     [1.]
     [0.]
     [1.]
     [0.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [0.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [0.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [0.]
     [1.]
     [1.]
     [0.]
     [0.]
     [1.]
     [0.]
     [1.]
     [0.]
     [0.]
     [0.]
     [1.]
     [1.]
     [0.]
     [0.]
     [1.]
     [1.]
     [0.]
     [1.]
     [0.]
     [1.]
     [0.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]
     [1.]] 
    Accuracy :  0.77470356

