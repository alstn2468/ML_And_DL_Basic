{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 9-1 : XOR을 위한 텐스플로우 딥넷트웍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XOR data set\n",
    "\n",
    "| A | B | X |\n",
    "| - | - | - |\n",
    "| 0 | 0 | 0 |\n",
    "| 0 | 1 | 1 |\n",
    "| 1 | 0 | 1 |\n",
    "| 1 | 1 | 0 |\n",
    "\n",
    "#### Boolean Expression\n",
    "$$\n",
    "X = A \\oplus B\n",
    "$$\n",
    "\n",
    "#### Logic Diagram Symbol\n",
    "\n",
    "<img src=\"./10.png\" width=\"400\" height=\"auto\" alt=\"아직 안만듬\">\n",
    "\n",
    "[[이미지 출처]](https://mathphysics.tistory.com/579)\n",
    "\n",
    "간단한 데이터셋이므로 따로 입력받지않고 **numpy array** 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array(\n",
    "    [\n",
    "        [0, 0],\n",
    "        [0, 1],\n",
    "        [1, 0],\n",
    "        [1, 1],\n",
    "    ],\n",
    "    dtype=np.float32\n",
    ")\n",
    "y_data = np.array(\n",
    "    [\n",
    "        [0],\n",
    "        [1],\n",
    "        [1],\n",
    "        [0],\n",
    "    ],\n",
    "    dtype=np.float32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Logistic Regression으로 해결하기\n",
    "**0**인지 **1**인지 예측하는 **Logistic Regression**사용<br/>\n",
    "$$X$$, $$Y$$에 맞게 **Weight**과 **Bias**를 결정해야한다.<br/>\n",
    "**Weigth**을 정할때에는 **크기**가 **중요**하다.<br/>\n",
    "입력값이 $$X_1$$, $$X_2$$로 2개고 출력값이 $$Y$$하나이기 때문에<br/>\n",
    "**Weight**의 크기는 **[2, 1]**의 크기다.<br/>\n",
    "**Bias**는 항상 **출력값의 갯수**와 같으므로 **[1]**이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "W = tf.Variable(tf.random_normal([2, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name=\"bias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Hypothesis\n",
    "**Sigmoid** 함수 사용<br/>\n",
    "\\begin{align} Sigmoid = \\frac{1}{1+e^{-x}} \\end{align}\n",
    "\n",
    "**행렬 곱셉** 후 **Sigmoid Function**에 넣는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Cost Function\n",
    "**Logistic Regression**의 **Cost Function**은 아래와 같다.<br/>\n",
    "$$\n",
    "C(H(x), y) = \n",
    "-Y * log(H(x)\n",
    "-(1 - Y) * log(1 - H(X))\n",
    "$$\n",
    "\n",
    "구해진 Cost를 가지고 **경사하강법**을 사용해 학습을 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis)\n",
    "                      + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Training\n",
    "위에 작성한 **Hypothesis**와 **Cost Function**을 사용해 학습을 진행<br/>\n",
    "`cast`함수를 사용해 **Hypothesis**의 값이 **0.5**보다 클경우 **True**로<br/>\n",
    "**0.5**보다 작을경우 **False**로 값을 바꾸어준다.<br/>\n",
    "또한 예측값과 결과값을 비교해 `cast`함수를 사용한 **결과의 평균**을 구해 **정확도**를 계산한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8513652 [[-2.1316051]\n",
      " [ 0.1544597]]\n",
      "1000 0.73598343 [[-1.1616342 ]\n",
      " [ 0.11189499]]\n",
      "2000 0.7089069 [[-0.6989508 ]\n",
      " [-0.00860908]]\n",
      "3000 0.6991427 [[-0.42546663]\n",
      " [-0.05454065]]\n",
      "4000 0.6955279 [[-0.2618011 ]\n",
      " [-0.06305098]]\n",
      "5000 0.6941303 [[-0.1630023 ]\n",
      " [-0.05659783]]\n",
      "6000 0.693566 [[-0.1026649 ]\n",
      " [-0.04571436]]\n",
      "7000 0.6933297 [[-0.06535754]\n",
      " [-0.03487875]]\n",
      "8000 0.69322795 [[-0.04200944]\n",
      " [-0.02569827]]\n",
      "9000 0.6931834 [[-0.02723129]\n",
      " [-0.01850214]]\n",
      "10000 0.69316345 [[-0.0177809 ]\n",
      " [-0.01310943]]\n",
      "\n",
      "Hypothesis:  [[0.5045799 ]\n",
      " [0.50130266]\n",
      " [0.5001348 ]\n",
      " [0.4968575 ]] \n",
      "Correct:  [[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:  0.75\n"
     ]
    }
   ],
   "source": [
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        _, cost_val, w_val = sess.run(\n",
    "            [train, cost, W], feed_dict={X: x_data, Y: y_data}\n",
    "        )\n",
    "\n",
    "        if step % 1000 == 0:\n",
    "            print(step, cost_val, w_val)\n",
    "            \n",
    "    h, c, a = sess.run(\n",
    "        [hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data}\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nHypothesis:\\n{h} \\nPredicted:\\n{p} \\nAccuracy:\\n{a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델이 정확하고 문제가 없음에도 불구하고 정확도가 높지않다.<br/>\n",
    "정확도를 올리기 위해서 **Neural Network**를 사용하면 된다.\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Using Neural Network\n",
    "여러개의 Layer를 사용하는 **NN**을 사용<br/>\n",
    "layer1의 결과물을 hypothesis에 넣어 한번더 학습시킨다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random_normal([2, 2]), name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal([2]), name='bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([2, 1]), name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([1]), name='bias2')\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이때 **weight의 크기**를 잘 정해주어야 한다.<br/>\n",
    "\n",
    "layer1의 입력값은 $$X_1$$, $$X_2$$로 **2개**이고 출력값의 갯수는<br/>\n",
    "임의로 결정하면 되므로 $$W_1$$의 크기는 **[2, 2]**로 정했다.<br/>\n",
    "출력값의 갯수를 2개로 결정했으니 **bias**의 크기는 **[2]**가 된다.<br/>\n",
    "\n",
    "layer1을 입력으로 받는 다른 layer의 입력값의 개수는<br/>\n",
    "**layer1의 입력값**인 **2개**로 같고 출력값은<br/>\n",
    "$$ \\bar{Y} $$이므로 **1개**이기 때문에 **weight**의 크기는 **[2. 1]**이다.<br/>\n",
    "**bias**의 크기는 출력값이 **1개**이기 때문에 **[1]**이다.<br/>\n",
    "\n",
    "따라서 결정된 Layer들의 **Weigth**과 **Bias**의 크기는 아래와 같다.<br/>\n",
    "\n",
    "|        | Weight | Bias |\n",
    "| ------ | ------ | ---- |\n",
    "| Layer1 | [2, 2] | [2]  |\n",
    "| Layer2 | [2, 1] | [1]  | \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Training\n",
    "2개의 Layer를 겹친 **Neural Network**를 이용해 한번 더 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7882031\n",
      "1000 0.66996527\n",
      "2000 0.56226295\n",
      "3000 0.46252495\n",
      "4000 0.3979395\n",
      "5000 0.13767728\n",
      "6000 0.058626205\n",
      "7000 0.036846615\n",
      "8000 0.026778355\n",
      "9000 0.020992192\n",
      "10000 0.01724169\n",
      "\n",
      "Hypothesis:\n",
      "[[0.01622479]\n",
      " [0.98648304]\n",
      " [0.97561294]\n",
      " [0.01419624]] \n",
      "Predicted:\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        _, cost_val = sess.run(\n",
    "            [train, cost], feed_dict={X: x_data, Y: y_data}\n",
    "        )\n",
    "        \n",
    "        if step % 1000 == 0:\n",
    "            print(step, cost_val)\n",
    "\n",
    "    # Accuracy report\n",
    "    h, p, a = sess.run(\n",
    "        [hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data}\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nHypothesis:\\n{h} \\nPredicted:\\n{p} \\nAccuracy:\\n{a}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
