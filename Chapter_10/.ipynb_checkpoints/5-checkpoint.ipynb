{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 9-2 : Tensor Board로 딥네트웍 들여다보기\n",
    "\n",
    "### Tensorboard\n",
    "진행사항을 한눈에 볼 수 있도록 해준다.<br/>\n",
    "**TF Graph** 시각화가 가능하다.\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Tensorboard 사용 단계\n",
    "1. 어떤 **Tensor**를 **logging**할지 결정\n",
    "    ```python\n",
    "    w2_hist = tf.summary.histogram(\"weight2\", W2)\n",
    "    cost_summ = tf.summary.scalar(\"cost\", cost)\n",
    "    ```\n",
    "2. **logging**할 데이터를 **merge**\n",
    "   ```python\n",
    "   summary = tf.summary.merge_all()\n",
    "   ```\n",
    "3. **Summary**(logging한 데이터)를 어디에 기록할지 설정\n",
    "    ```python\n",
    "    wrtier = tf.summary.FileWriter(\"./logs\")\n",
    "    wrtier.add_graph(sess.graph)\n",
    "    ```\n",
    "4. **Session**을 열어 **Summary**실행 및 파일에 기록\n",
    "    ```python\n",
    "    s, _ = sess.run([summary, optimizer], feed_dict=feed_dict)\n",
    "    writer.add_summary(s, global_step=global_step)\n",
    "    ```\n",
    "5. 터미널에서 **Tensorboard**명령어 실행\n",
    "    ```\n",
    "    tensoorboard --logdir=./logs\n",
    "    ```\n",
    "    \n",
    "<br/>\n",
    "\n",
    "### Logging할 데이터\n",
    "값이 하나(scalar)일 경우 `tf.summary.scalar`사용<br/>\n",
    "값이 여러개(vector)일 경우 `tf.summary.histogram`사용\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Tensor 그래프 그리기\n",
    "Tensor그래프를 한번에 펼쳐놓으면 보기 힘들기 때문에<br/>\n",
    "**Tensorboard**의 `tf.name_scope`함수를 이용해 **계층별** 정리<br/>\n",
    "\n",
    "<br/>\n",
    "\n",
    "### 여러개의 값으로 비교해보고 싶을 때\n",
    "ex) learning_rate = 0.1 vs learning_rate 0.01<br/>\n",
    "\n",
    "**Multiple runs** 사용<br/>\n",
    "log를 저장하는 **dir**경로를 다르게 주고<br/>\n",
    "부모의 디렉토리의 경로로 그래프를 실행<br/>\n",
    "\n",
    "```\n",
    "logs\n",
    "├─ run0_1\n",
    "├─ run0_01\n",
    "└─ run0_001\n",
    "```\n",
    "\n",
    "위와 같은 경우<br/>\n",
    "`tensorboard --logidr=./logs/run0_1`<br/>\n",
    "`tensorboard --logidr=./logs/run0_01`<br/>\n",
    "`tensorboard --logidr=./logs/run0_01`<br/>\n",
    "의 명령어로 Tensorboard를 실행시킬 수 있지만<br/>\n",
    "\n",
    "`tensorboard --logidr=./logs`와 같이<br/>\n",
    "상위 디렉토리로 Tensorboard를 실행시키면 비교가 가능<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0360026\n",
      "1000 0.08819285\n",
      "2000 0.01809669\n",
      "3000 0.007408534\n",
      "4000 0.0037033758\n",
      "5000 0.0020230967\n",
      "6000 0.0011570905\n",
      "7000 0.0006789303\n",
      "8000 0.00040425535\n",
      "9000 0.00024286224\n",
      "10000 0.00014668413\n",
      "\n",
      "Hypothesis:\n",
      "[[2.3283975e-04]\n",
      " [9.9987853e-01]\n",
      " [9.9987864e-01]\n",
      " [1.1060548e-04]] \n",
      "Predicted:\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]] \n",
      "Accuracy:\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.array(\n",
    "    [\n",
    "        [0, 0], \n",
    "        [0, 1], \n",
    "        [1, 0], \n",
    "        [1, 1]\n",
    "    ], \n",
    "    dtype=np.float32\n",
    ")\n",
    "y_data = np.array(\n",
    "    [\n",
    "        [0], \n",
    "        [1], \n",
    "        [1], \n",
    "        [0]\n",
    "    ], \n",
    "    dtype=np.float32\n",
    ")\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 2], name=\"x\")\n",
    "Y = tf.placeholder(tf.float32, [None, 1], name=\"y\")\n",
    "\n",
    "with tf.name_scope(\"Layer1\"):\n",
    "    W1 = tf.Variable(tf.random_normal([2, 2]), name=\"weight_1\")\n",
    "    b1 = tf.Variable(tf.random_normal([2]), name=\"bias_1\")\n",
    "    layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "    tf.summary.histogram(\"W1\", W1)\n",
    "    tf.summary.histogram(\"b1\", b1)\n",
    "    tf.summary.histogram(\"Layer1\", layer1)\n",
    "\n",
    "\n",
    "with tf.name_scope(\"Layer2\"):\n",
    "    W2 = tf.Variable(tf.random_normal([2, 1]), name=\"weight_2\")\n",
    "    b2 = tf.Variable(tf.random_normal([1]), name=\"bias_2\")\n",
    "    hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "    tf.summary.histogram(\"W2\", W2)\n",
    "    tf.summary.histogram(\"b2\", b2)\n",
    "    tf.summary.histogram(\"Hypothesis\", hypothesis)\n",
    "\n",
    "with tf.name_scope(\"Cost\"):\n",
    "    cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "    tf.summary.scalar(\"Cost\", cost)\n",
    "\n",
    "with tf.name_scope(\"Train\"):\n",
    "    train = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))\n",
    "tf.summary.scalar(\"accuracy\", accuracy)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    merged_summary = tf.summary.merge_all()\n",
    "    writer = tf.summary.FileWriter(\"./xor_logs\")\n",
    "    writer.add_graph(sess.graph)\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(10001):\n",
    "        _, summary, cost_val = sess.run(\n",
    "            [train, merged_summary, cost], feed_dict={X: x_data, Y: y_data}\n",
    "        )\n",
    "        writer.add_summary(summary, global_step=step)\n",
    "\n",
    "        if step % 1000 == 0:\n",
    "            print(step, cost_val)\n",
    "\n",
    "    h, p, a = sess.run(\n",
    "        [hypothesis, predicted, accuracy], feed_dict={X: x_data, Y: y_data}\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nHypothesis:\\n{h} \\nPredicted:\\n{p} \\nAccuracy:\\n{a}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
