{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression 의 cost 최소화의 TensorFlow 구현(new)\n",
    "\n",
    "### Simplified hypothesis\n",
    "\n",
    "\\begin{align}\n",
    "H(x) = Wx \\\\\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "cost(W) = \\frac{1}{m}\\sum_{i=1}^m(Wx^{(i)} - y^{(i)})^2 \\\\\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1413e5f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = [1, 2, 3]\n",
    "Y = [1, 2, 3]\n",
    "\n",
    "W = tf.placeholder(tf.float32)\n",
    "\n",
    "# Our hypothesis for linear model X * W\n",
    "hypothesis = X * W\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Variables for plotting cost function\n",
    "W_history = []\n",
    "cost_history = []\n",
    "\n",
    "for i in range(-30, 50):\n",
    "    curr_W = i * 0.1\n",
    "    curr_cost = sess.run(cost, feed_dict={W: curr_W})\n",
    "    W_history.append(curr_W)\n",
    "    cost_history.append(curr_cost)\n",
    "\n",
    "# Show the cost function\n",
    "plt.plot(W_history, cost_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Gradient descent\n",
    "\n",
    "\\begin{align}\n",
    "W := W - a\\frac{1}{m}\\sum_{i=1}^m(Wx^{(i)} - y^{(i)})x^{(i)} \\\\\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.1058571 [0.513205]\n",
      "1 0.3145549 [0.740376]\n",
      "2 0.089473374 [0.8615339]\n",
      "3 0.025450192 [0.9261514]\n",
      "4 0.0072391774 [0.9606141]\n",
      "5 0.0020591363 [0.9789942]\n",
      "6 0.0005857132 [0.9887969]\n",
      "7 0.00016660336 [0.994025]\n",
      "8 4.7388196e-05 [0.99681336]\n",
      "9 1.34802e-05 [0.99830043]\n",
      "10 3.8339094e-06 [0.9990936]\n",
      "11 1.0903422e-06 [0.9995166]\n",
      "12 3.102087e-07 [0.99974215]\n",
      "13 8.822294e-08 [0.9998625]\n",
      "14 2.5065395e-08 [0.9999267]\n",
      "15 7.1346826e-09 [0.9999609]\n",
      "16 2.025999e-09 [0.99997914]\n",
      "17 5.784351e-10 [0.99998885]\n",
      "18 1.6579331e-10 [0.99999404]\n",
      "19 4.694911e-11 [0.99999684]\n",
      "20 1.2998195e-11 [0.99999833]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_data = [1, 2, 3]\n",
    "y_data = [1, 2, 3]\n",
    "\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# Our hypothesis for linear model X * W\n",
    "hypothesis = X * W\n",
    "\n",
    "# cost/loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize : Gradient Descent using derivative\n",
    "# W -= learning_rate * derivative\n",
    "learning_rate = 0.1\n",
    "gradient = tf.reduce_mean((W * X - Y) * X)\n",
    "descent = W - learning_rate * gradient\n",
    "update = W.assign(descent)\n",
    "\n",
    "# Launch the graph in a session.\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(21):\n",
    "    sess.run(update, feed_dict={X: x_data, Y: y_data})\n",
    "    print(step, sess.run(cost, feed_dict={X: x_data, Y: y_data}), sess.run(W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Output when W = 5\n",
    "- **경사하강법**이 잘 되는지 테스트 \n",
    "- 오른쪽에서 하강"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.0\n",
      "1 1.2666664\n",
      "2 1.0177778\n",
      "3 1.0011852\n",
      "4 1.000079\n",
      "5 1.0000052\n",
      "6 1.0000004\n",
      "7 1.0\n",
      "8 1.0\n",
      "9 1.0\n",
      "10 1.0\n",
      "11 1.0\n",
      "12 1.0\n",
      "13 1.0\n",
      "14 1.0\n",
      "15 1.0\n",
      "16 1.0\n",
      "17 1.0\n",
      "18 1.0\n",
      "19 1.0\n",
      "20 1.0\n",
      "21 1.0\n",
      "22 1.0\n",
      "23 1.0\n",
      "24 1.0\n",
      "25 1.0\n",
      "26 1.0\n",
      "27 1.0\n",
      "28 1.0\n",
      "29 1.0\n",
      "30 1.0\n",
      "31 1.0\n",
      "32 1.0\n",
      "33 1.0\n",
      "34 1.0\n",
      "35 1.0\n",
      "36 1.0\n",
      "37 1.0\n",
      "38 1.0\n",
      "39 1.0\n",
      "40 1.0\n",
      "41 1.0\n",
      "42 1.0\n",
      "43 1.0\n",
      "44 1.0\n",
      "45 1.0\n",
      "46 1.0\n",
      "47 1.0\n",
      "48 1.0\n",
      "49 1.0\n",
      "50 1.0\n",
      "51 1.0\n",
      "52 1.0\n",
      "53 1.0\n",
      "54 1.0\n",
      "55 1.0\n",
      "56 1.0\n",
      "57 1.0\n",
      "58 1.0\n",
      "59 1.0\n",
      "60 1.0\n",
      "61 1.0\n",
      "62 1.0\n",
      "63 1.0\n",
      "64 1.0\n",
      "65 1.0\n",
      "66 1.0\n",
      "67 1.0\n",
      "68 1.0\n",
      "69 1.0\n",
      "70 1.0\n",
      "71 1.0\n",
      "72 1.0\n",
      "73 1.0\n",
      "74 1.0\n",
      "75 1.0\n",
      "76 1.0\n",
      "77 1.0\n",
      "78 1.0\n",
      "79 1.0\n",
      "80 1.0\n",
      "81 1.0\n",
      "82 1.0\n",
      "83 1.0\n",
      "84 1.0\n",
      "85 1.0\n",
      "86 1.0\n",
      "87 1.0\n",
      "88 1.0\n",
      "89 1.0\n",
      "90 1.0\n",
      "91 1.0\n",
      "92 1.0\n",
      "93 1.0\n",
      "94 1.0\n",
      "95 1.0\n",
      "96 1.0\n",
      "97 1.0\n",
      "98 1.0\n",
      "99 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# tf Graph Input\n",
    "X = [1, 2, 3]\n",
    "Y = [1, 2, 3]\n",
    "\n",
    "# Set wrong model weights\n",
    "W = tf.Variable(5.0)\n",
    "\n",
    "# Linear model\n",
    "hypothesis = X * W\n",
    "\n",
    "# cost/Loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize : Gradient Descent Magic\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initializes global variables int he graph\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(100):\n",
    "    print(step, sess.run(W))\n",
    "    sess.run(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Output when W = -3\n",
    "- **경사하강법**이 잘 되는지 테스트\n",
    "- 왼쪽에서 하강"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 -3.0\n",
      "1 0.7333336\n",
      "2 0.98222226\n",
      "3 0.9988148\n",
      "4 0.99992096\n",
      "5 0.9999947\n",
      "6 0.99999964\n",
      "7 0.99999994\n",
      "8 1.0\n",
      "9 1.0\n",
      "10 1.0\n",
      "11 1.0\n",
      "12 1.0\n",
      "13 1.0\n",
      "14 1.0\n",
      "15 1.0\n",
      "16 1.0\n",
      "17 1.0\n",
      "18 1.0\n",
      "19 1.0\n",
      "20 1.0\n",
      "21 1.0\n",
      "22 1.0\n",
      "23 1.0\n",
      "24 1.0\n",
      "25 1.0\n",
      "26 1.0\n",
      "27 1.0\n",
      "28 1.0\n",
      "29 1.0\n",
      "30 1.0\n",
      "31 1.0\n",
      "32 1.0\n",
      "33 1.0\n",
      "34 1.0\n",
      "35 1.0\n",
      "36 1.0\n",
      "37 1.0\n",
      "38 1.0\n",
      "39 1.0\n",
      "40 1.0\n",
      "41 1.0\n",
      "42 1.0\n",
      "43 1.0\n",
      "44 1.0\n",
      "45 1.0\n",
      "46 1.0\n",
      "47 1.0\n",
      "48 1.0\n",
      "49 1.0\n",
      "50 1.0\n",
      "51 1.0\n",
      "52 1.0\n",
      "53 1.0\n",
      "54 1.0\n",
      "55 1.0\n",
      "56 1.0\n",
      "57 1.0\n",
      "58 1.0\n",
      "59 1.0\n",
      "60 1.0\n",
      "61 1.0\n",
      "62 1.0\n",
      "63 1.0\n",
      "64 1.0\n",
      "65 1.0\n",
      "66 1.0\n",
      "67 1.0\n",
      "68 1.0\n",
      "69 1.0\n",
      "70 1.0\n",
      "71 1.0\n",
      "72 1.0\n",
      "73 1.0\n",
      "74 1.0\n",
      "75 1.0\n",
      "76 1.0\n",
      "77 1.0\n",
      "78 1.0\n",
      "79 1.0\n",
      "80 1.0\n",
      "81 1.0\n",
      "82 1.0\n",
      "83 1.0\n",
      "84 1.0\n",
      "85 1.0\n",
      "86 1.0\n",
      "87 1.0\n",
      "88 1.0\n",
      "89 1.0\n",
      "90 1.0\n",
      "91 1.0\n",
      "92 1.0\n",
      "93 1.0\n",
      "94 1.0\n",
      "95 1.0\n",
      "96 1.0\n",
      "97 1.0\n",
      "98 1.0\n",
      "99 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# tf Graph Input\n",
    "X = [1, 2, 3]\n",
    "Y = [1, 2, 3]\n",
    "\n",
    "# Set wrong model weights\n",
    "W = tf.Variable(-3.0)\n",
    "\n",
    "# Linear model\n",
    "hypothesis = X * W\n",
    "\n",
    "# cost/Loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize : Gradient Descent Magic\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initializes global variables int he graph\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(100):\n",
    "    print(step, sess.run(W))\n",
    "    sess.run(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Optional : compute_gradient and apply_gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [37.333332, 5.0, [(37.333336, 5.0)]]\n",
      "1 [2.4888866, 1.2666664, [(2.4888866, 1.2666664)]]\n",
      "2 [0.1659259, 1.0177778, [(0.1659259, 1.0177778)]]\n",
      "3 [0.011061668, 1.0011852, [(0.011061668, 1.0011852)]]\n",
      "4 [0.00073742867, 1.000079, [(0.00073742867, 1.000079)]]\n",
      "5 [4.895528e-05, 1.0000052, [(4.8955284e-05, 1.0000052)]]\n",
      "6 [3.0994415e-06, 1.0000004, [(3.0994415e-06, 1.0000004)]]\n",
      "7 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "8 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "9 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "10 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "11 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "12 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "13 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "14 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "15 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "16 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "17 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "18 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "19 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "20 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "21 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "22 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "23 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "24 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "25 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "26 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "27 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "28 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "29 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "30 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "31 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "32 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "33 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "34 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "35 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "36 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "37 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "38 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "39 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "40 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "41 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "42 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "43 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "44 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "45 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "46 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "47 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "48 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "49 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "50 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "51 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "52 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "53 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "54 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "55 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "56 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "57 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "58 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "59 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "60 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "61 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "62 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "63 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "64 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "65 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "66 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "67 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "68 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "69 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "70 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "71 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "72 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "73 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "74 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "75 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "76 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "77 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "78 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "79 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "80 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "81 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "82 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "83 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "84 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "85 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "86 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "87 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "88 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "89 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "90 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "91 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "92 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "93 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "94 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "95 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "96 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "97 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "98 [0.0, 1.0, [(0.0, 1.0)]]\n",
      "99 [0.0, 1.0, [(0.0, 1.0)]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# tf Graph Input\n",
    "X = [1, 2, 3]\n",
    "Y = [1, 2, 3]\n",
    "\n",
    "# Set wrong model weights\n",
    "W = tf.Variable(5.)\n",
    "\n",
    "# Linear model\n",
    "hypothesis = X * W\n",
    "\n",
    "# Manual gradient\n",
    "gradient = tf.reduce_mean((W * X - Y) * X) * 2\n",
    "\n",
    "# cost/Loss function\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "# Minimize : Gradient Descent Magic\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "\n",
    "# Get gradients\n",
    "gvs = optimizer.compute_gradients(cost, [W])\n",
    "# Apply gradients\n",
    "apply_gradients = optimizer.apply_gradients(gvs)\n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initializes global variables int he graph\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(100):\n",
    "    print(step, sess.run([gradient, W, gvs]))\n",
    "    sess.run(apply_gradients)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
